{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook: Calwebb_coron3 for MIRI coronagraphic imaging\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: MIRI, NIRCam\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction](#intro)\n",
    "<br> [JWST CalWG Algorithm](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description](#test_descr)\n",
    "<br> [Data Description](#data_descr)\n",
    "<br> [Imports](#imports)\n",
    "<br> [Load Input Data](#data_load)\n",
    "<br> [Run the Pipeline](#run_pipeline)\n",
    "<br> [Examine Outputs](#testing) \n",
    "<br> [About This Notebook](#about)\n",
    "<br>    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "This is the validation notebook for stage 3 coronagraphic processing of MIRI 4QPM exposures. The stage 3 coronagraphic pipeline ([`calwebb_coron3`](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_coron3.html#calwebb-coron3)) is to be applied to associations of calibrated NIRCam and MIRI coronagraphic exposures, and is used to produce PSF-subtracted, resampled, combined images of the source object. For more information on `calwebb_coron3`, please visit the links below.\n",
    "\n",
    "> Module description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_coron3.html#calwebb-coron3\n",
    "\n",
    "> Pipeline code: https://github.com/spacetelescope/jwst/blob/master/jwst/coron/\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "\n",
    "The algorithms for `CALWEBB_CORON3` are as follows:\n",
    "\n",
    "- **Assemble Reference PSFs**: <br>\n",
    "All the available reference PSFs are assembled into the appropriate association.\n",
    "\n",
    "\n",
    "- **Outlier detection**: <br> \n",
    "An iterative sigma clipping algorithm is used in pixel coordinates on the image stack. The presence of an outlier results in a pixel flag being set.\n",
    "\n",
    "\n",
    "- **Align reference PSFs**: <br>\n",
    "The reference PSFs are aligned with the target observation using the Fourier LSQ algorithm to measure the shifts and the Fourier Shift algorithm to apply the shifts to each reference PSF integration.\n",
    "\n",
    "\n",
    "- **Reference PSF subtraction**: <br>\n",
    "The reference PSF that is subtracted from each target integration is created using the list of reference PSFs and the KLIP algorithm. \n",
    "\n",
    "\n",
    "- **Image Combination**: <br>\n",
    "The target images (including those at different rotations) are combined into a single combined image using the AstroDrizzle code (with the output pixel size set to the input pixel size).\n",
    "\n",
    "\n",
    "- **Updated Exposure Level Products**: <br>\n",
    "The exposure level products are re-created to provide the highest quality products that include the results of the ensemble processing (updated WCS, matching backgrounds, and 2nd pass outlier detection). \n",
    "\n",
    "<BR>\n",
    "\n",
    "The current status of these algorithms are summarized in the link below:\n",
    "\n",
    "> https://outerspace.stsci.edu/display/JWSTCC/CALWEBB_CORON3\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "- **JWST**: James Webb Space Telescope ([see documentation](https://jwst-docs.stsci.edu/))\n",
    "- **MIRI**: Mid-Infrared Instrument ([see documentation](https://jwst-docs.stsci.edu/mid-infrared-instrument))\n",
    "- **NIRCam**: Near-Infrared Instrument ([see documentation](https://jwst-docs.stsci.edu/near-infrared-camera))\n",
    "- **4QPM**: 4 Quadrant Phase Mask ([see documentation](https://jwst-docs.stsci.edu/mid-infrared-instrument/miri-instrumentation/miri-coronagraphs#MIRICoronagraphs-4qpm))\n",
    "- **Lyot**: coronagraph design incorporating a classical Lyot spot ([see documentation](https://jwst-docs.stsci.edu/mid-infrared-instrument/miri-instrumentation/miri-coronagraphs#MIRICoronagraphs-lyotcoron))\n",
    "- **PanCAKE**: an in-house tool at STScI used to simulate coronagraphic PSFs \n",
    "([see documentation](https://github.com/spacetelescope/pandeia-coronagraphy))\n",
    "- **SGD**: Small Grid Dither \n",
    "([see documentation](https://jwst-docs.stsci.edu/methods-and-roadmaps/jwst-high-contrast-imaging/hci-proposal-planning/hci-small-grid-dithers))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    " [Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_descr\"></a>\n",
    "# Test Description\n",
    "\n",
    "This notebook tests the the following steps applied by `calwebb_coron3` for pipeline version == **'0.17.1'**.\n",
    "\n",
    " - [**stack_refs**](#stack_refs)\n",
    " - [**align_refs**](#align-refs)\n",
    " - [**klip**](#klip)\n",
    "\n",
    "These tests are performed using simulated MIRI 4QPM coronagraphic data (see [Data Description](#data_descr)).\n",
    "\n",
    "This notebook does not test the following steps applied by the `calwebb_coron3` pipeline:\n",
    "\n",
    " - **outlier_detection**\n",
    " - **resample**\n",
    " \n",
    "See [Required Future Testing](#future_tests) for details.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "\n",
    "### Input Data:\n",
    "\n",
    "The set of data used in these tests were generated using `PanCAKE` and edited to enable processing through the `calwebb_coron3` pipeline. The simulated data was generated for the MIRI 1065C 4QPM coronagraph and consists of one science exposure and nine reference PSF exposures based on the following observation scenario: (1) a science observation of a target star with two faint companions, followed by (2) the execution of a 9-point small grid dither (SGD) pattern on a PSF calibrator of similar magnitude, to obtain a set of 9 slightly offset reference PSF observations.\n",
    "\n",
    "\n",
    "The data has the following naming format:\n",
    "- Science exposure: \n",
    "\n",
    "      'new_targ_0.fits' \n",
    "\n",
    "- Reference PSF exposures:\n",
    "\n",
    "      'new_ref_0.fits', 'new_ref_1.fits', 'new_ref_2.fits', 'new_ref_3.fits', 'new_ref_4.fits', 'new_ref_5.fits', 'new_ref_6.fits', 'new_ref_7.fits', 'new_ref_8.fits'\n",
    "      \n",
    "\n",
    "\n",
    "### Refence Files:\n",
    "\n",
    "The `align_refs` step requires a PSFMASK reference file containing a 2D mask thatâ€™s used as a weight function when computing shifts between images. \n",
    "\n",
    "> File description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/align_refs/description.html#psfmask-reffile\n",
    "\n",
    "Currently the PSFMASK reference files ingested into CRDS are incorrect (wrong shape and incorrectly centered around coronagraphic obstructions), therefore an updated file is used for these tests:\n",
    "\n",
    "       'psfmask_MIRI_4QPM_1065.fits'\n",
    " \n",
    "\n",
    "### Association File:\n",
    "\n",
    "Currently the individual stage 3 coronagraphic processing steps can only be run in a convenient way by running the `calwebb_coron3` pipeline on an association (ASN) file that lists the various science target and reference PSF exposures to be processed. \n",
    "\n",
    "> Level 3 Associations documentation: https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/level3_asn_rules.html\n",
    "\n",
    "We use the following ASN file for the purpose of these tests:\n",
    "\n",
    "       'test.yml'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "\n",
    "* `astropy.io` for opening fits files\n",
    "* `jwst` is the JWST Calibration Pipeline\n",
    "* `jwst.Coron3Pipeline` is the pipeline being tested\n",
    "* `matplotlib.pyplot.plt` to generate plots\n",
    "* `numpy` for array calculations and manipulation\n",
    "* `download_file` for downloading and accessing files\n",
    "* `ipywidgets`, `IPython.display.display,clear_output` to display images.\n",
    "* `ci_watson.arartifactory_helpers.get_bigdata` to download data\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwst\n",
    "from jwst.pipeline import Coron3Pipeline\n",
    "from astropy.io import fits\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from astropy.utils.data import download_file\n",
    "%config InlineBackend.close_figures=False # To prevent automatic figure display when execution of the cell ends\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display,clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jwst.__version__\n",
    "# should out '1.3.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import shutil\n",
    "data_dir = TemporaryDirectory()\n",
    "shutil.copy(\"jwst_calcoron3_miri_test.yml\", os.path.join(data_dir.name, \"jwst_calcoron3_miri_test.yml\"))\n",
    "os.chdir(data_dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some plotting helper functions that will overlay the SIAF aperture boundaries and reference point on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download science image\n",
    "\n",
    "target_psf_fn = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_targ.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download PSF reference images\n",
    "    \n",
    "new_ref_0 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_0.fits')\n",
    "\n",
    "new_ref_1 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_1.fits')\n",
    "\n",
    "new_ref_2 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_2.fits')\n",
    "\n",
    "new_ref_3 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_3.fits')\n",
    "\n",
    "new_ref_4 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_4.fits')\n",
    "\n",
    "new_ref_5 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_5.fits')\n",
    "\n",
    "new_ref_6 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_6.fits')\n",
    "\n",
    "new_ref_7 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_7.fits')\n",
    "             \n",
    "new_ref_8 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'calwebb_coron3',\n",
    "                     'coron3_miri_test', \n",
    "                     'new_ref_8.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update test data headers with CORONMSK keyword, which is currently missing\n",
    "img_files = [target_psf_fn,\n",
    "             new_ref_0, new_ref_1, new_ref_2,\n",
    "             new_ref_3, new_ref_4, new_ref_5, \n",
    "             new_ref_6, new_ref_7, new_ref_8]\n",
    "\n",
    "for f in img_files:\n",
    "    with fits.open(f) as hdul:\n",
    "        hdul[0].header['CORONMSK'] = f'4QPM_{fits.getval(target_psf_fn, \"SUBARRAY\", 0)[-4:]}'\n",
    "        hdul.writeto(hdul.filename(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array containing the input reference images\n",
    "input_ref_images = [fits.getdata(new_ref_8)[0], fits.getdata(new_ref_7)[0], fits.getdata(new_ref_6)[0], \n",
    "                    fits.getdata(new_ref_5)[0],fits.getdata(new_ref_4)[0], fits.getdata(new_ref_3)[0], \n",
    "                    fits.getdata(new_ref_2)[0], fits.getdata(new_ref_1)[0], fits.getdata(new_ref_0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<a id=\"run_pipeline\"></a>\n",
    "\n",
    "\n",
    "------------\n",
    "\n",
    "# Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_dir = 'jwst_calcoron3_miri_test.yml'                       # Define ASN file\n",
    "myCoron3Pipeline = Coron3Pipeline()                              \n",
    "myCoron3Pipeline.resample.skip = True                          # Skip resample step\n",
    "myCoron3Pipeline.save_results = True                             \n",
    "myCoron3Pipeline.output_dir = os.getcwd() \n",
    "myCoron3Pipeline.run(asn_dir)                                  # run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<a id=\"testing\"></a>\n",
    "--------------\n",
    "# Examine Output Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, here are some plotting utitlies to overlay SIAF information about the subarray\n",
    "# over the images\n",
    "\n",
    "from pysiaf import Siaf\n",
    "miri_siaf = Siaf(\"MIRI\")\n",
    "aper_name = f'MIRIM_{fits.getval(target_psf_fn, \"SUBARRAY\", 0)}'\n",
    "\n",
    "def plot_with_aper(img, aper_name=aper_name, ax=None, fig_kws={}, plot_kws={}):\n",
    "    \"\"\"\n",
    "    Plot an image with the aperture outline and reference point overlaid\n",
    "    img: 2-D image\n",
    "    aper_name: SIAF-searchable MIRI aperture name. Must match the image footprint.\n",
    "    ax [None]: axis to draw on. If None, creates new figure\n",
    "    fig_kws [{}]: figure arguments to pass to plt.subplots()\n",
    "    plot_kws [{}]: arguments to pass to the plotting function (e.g. ax.imshow(img, **plot_kws))\n",
    "    Output:\n",
    "    returns the current fig and ax as a tuple (fig, ax)\n",
    "    \"\"\"\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(1, 1, **fig_kws)\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "    ax.set_xlabel(\"subarray pixel\")\n",
    "    ax.set_ylabel(\"subarray pixel\")\n",
    "    \n",
    "    aper = Siaf(\"MIRI\")[aper_name]\n",
    "    aper.plot(frame='sci', ax=ax, fill=False, mark_ref=True, c='C1')\n",
    "\n",
    "    # using the aperture corner definitions to set the plot coordinates\n",
    "    # ensures that the plotted image will match up with the aperture's \n",
    "    # features, e.g. the reference point\n",
    "    corners = aper.corners('sci')\n",
    "    x, y = np.meshgrid(np.arange(corners[0].min(), corners[0].max()+1, 1),\n",
    "                       np.arange(corners[1].min(), corners[1].max()+1, 1))\n",
    "    \n",
    "    ax.pcolor(x, y, img, zorder=-1, **plot_kws)\n",
    "    \n",
    "    lolim, hilim = np.min(corners, axis=1), np.max(corners, axis=1)\n",
    "    ax.set_xlim(lolim[0]-5, hilim[0]+5)\n",
    "    ax.set_ylim(lolim[1]-5, hilim[1]+5)\n",
    "    return fig, ax\n",
    "\n",
    "def plot_stack_with_aper(images, aper_name=aper_name, fig_kws={}, plot_kws={}):\n",
    "    \"\"\"\n",
    "    Similar to plot_with_aper, but you pass a cube in and it makes one plot for each image.\n",
    "    This function creates its own figure and axes\n",
    "\n",
    "    images: 3-D cube of images\n",
    "    aper_name: SIAF-searchable MIRI aperture name. Must match the image footprint.\n",
    "    fig_kws [{}]: figure arguments to pass to plt.subplots()\n",
    "    plot_kws [{}]: argumets to pass to the plotting function (e.g. ax.imshow(img, **plot_kws))\n",
    "    Output:\n",
    "    returns the created figure\n",
    "    \"\"\"\n",
    "    # initialize the figure\n",
    "    ncols = 3\n",
    "    nrows = np.ceil(images.shape[0]/ncols).astype(int)\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols,\n",
    "                             figsize=(6*ncols, 6*nrows),\n",
    "                             squeeze=False)\n",
    "    plot_kws = {'vmin':0, 'vmax': 20}\n",
    "    for index, (ax, img) in enumerate(zip(axes.ravel(), images)):\n",
    "        plot_with_aper(img, aper_name=aper_name, ax=ax, \n",
    "                       fig_kws={}, plot_kws=plot_kws);\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stack_refs\"></a>\n",
    "###  `stack_refs`:  Stack PSF References (*'_psfstack' product*)\n",
    "\n",
    "The role of the `stack_refs` step is to stack all of the PSF reference exposures (specified in the input ASN file) into a single `CubeModel` for use by subsequent coronagraphic steps. The size of the stack should be equal to the sum of the number of integrations in each input PSF exposure.  The image data are simply copied and reformatted and should not be modified in any way.\n",
    "\n",
    "*Output*: **3D PSF Image Stack** <br>\n",
    "*File suffix*: **'_psfstack'**\n",
    "\n",
    "> Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/stack_refs/index.html#stack-refs-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_cube_hdu = fits.open('jw10005-miri-mask1065_psfstack.fits')\n",
    "ref_images = stacked_cube_hdu[1].data\n",
    "print(stacked_cube_hdu.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'_psfstack' data product dimensions: \"+str(ref_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show just the stacked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kws = {'vmin':0, 'vmax': 20}\n",
    "fig = plot_stack_with_aper(ref_images, plot_kws=plot_kws)\n",
    "fig.suptitle(\"Stacked references\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the stacked images, each differenced against the one before it (the first image is shown as normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract each image from the one before it\n",
    "images = np.diff(ref_images, axis=0, prepend=0)\n",
    "\n",
    "plot_kws = {'vmin':0, 'vmax': 20}\n",
    "fig = plot_stack_with_aper(images, plot_kws=plot_kws)\n",
    "fig.suptitle(\"Stacked References, Differenced\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stack_psfs` step has sucessfully stacked the reference PSF exposures into a single 3D '*_psfstack*' product, with size equal to the sum of the number of integrations in each input PSF exposure *(9)*. To confirm that the image data has not been modified, the input PSF images are subtracted from each image in the stack below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "<a id=\"align_refs\"></a>\n",
    "\n",
    "\n",
    "### `align_refs`:  Align PSF References (*'_psfalign' product*)\n",
    "\n",
    "The role of the `align_refs` step is to align the coronagraphic PSF images with science target images. It does so by computing the offsets between the science target and reference PSF images, and shifts the PSF images into alignment. The output of the `align_refs` step is a 4D data product, where the 3rd axis has length equal to the total number of reference PSF images in the input PSF stack and the 4th axis has length equal to the number of integrations in the input science target product. \n",
    "\n",
    "*Output*: **4D aligned PSF Images** <br>\n",
    "*File suffix*: **_psfalign**\n",
    "\n",
    "\n",
    "> Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/align_refs/index.html#align-refs-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cube_hdu = fits.open('new_targ_c1001_psfalign.fits')\n",
    "aligned_cube_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cube_data = (aligned_cube_hdu[1].data)\n",
    "print(\"'_psfalign' data product dimensions: \" + str(aligned_cube_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cubes after alignment\n",
    "images = aligned_cube_data[0]\n",
    "\n",
    "plot_kws = {'vmin':0, 'vmax': 20}\n",
    "fig = plot_stack_with_aper(images, plot_kws=plot_kws)\n",
    "fig.suptitle(\"Aligned References\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract each aligned image from the one before it\n",
    "images = np.diff(aligned_cube_data[0], axis=0, prepend=0)\n",
    "    \n",
    "plot_kws = {'vmin':0, 'vmax': 20}\n",
    "fig = plot_stack_with_aper(images, plot_kws=plot_kws)\n",
    "fig.suptitle(\"Aligned References, Differenced\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `align_refs` step has successfully aligned the psf images - note the smaller residuals in the difference images\n",
    "\n",
    "The output is indeed a 4D '*_psfalign*' product, where the 3rd axis has length equal to the total number of reference images in the input PSF stack *(9)* and 4th axis equal to the number of integrations in the input science target image *(1)*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "<a id=\"klip\"></a>\n",
    "### `klip`:  Reference PSF Subtraction\n",
    "\n",
    "The role of the `klip` step is to apply the Karhunen-Loeve Image Plane (KLIP) algorithm on the science target images, using an accompanying set of aligned reference PSF images (result of the `align_refs` step) in order to fit and subtract an optimal PSF from the science target image. The PSF fitting and subtraction is applied to each integration image independently. The output is a 3D stack of PSF-subtracted images of the science target, having the same dimensions as the input science target product.\n",
    "\n",
    "*Output*: **3D PSF-subtracted image** <br>\n",
    "*File suffix*: **_psfsub**\n",
    "\n",
    "> Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/klip/index.html#klip-step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_hdu = fits.open('new_targ_c1001_psfsub.fits')\n",
    "sub_hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtracted_image = sub_hdu[1].data\n",
    "print(\"Science target image dimensions: \" + str(fits.getdata(target_psf_fn, 'SCI').shape))\n",
    "print(\"PSF subtracted image dimensions: \" + str(subtracted_image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the PSF subtracted image has the same dimensions as the input target image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "fig, ax = plot_with_aper(subtracted_image[0], aper_name=aper_name, ax=ax, plot_kws={'vmin':0,'vmax':10})\n",
    "ax.set_title(\"PSF subtracted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `klip` step has successfully made a synthetic psf reference image and subtracted it from the target PSF - indeed, the two companion PSFs that were injected into the target PSF are now visable. The output stack of PSF-subtracted images has the same dimensions as the input science target product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<br>\n",
    "<a id=\"future_tests\"></a>\n",
    "--------------\n",
    "# Required Future Testing\n",
    "\n",
    "- Testing of the `outlier_detection` step in conjunction with the three steps above.\n",
    "- Testing of the `resample` step using a data set containing a reference PSF target with astrophysical contamination (i.e. a companion) and target images at two different orientations (simulating referenced differential imaging) - whereby the the `resample` step should correctly combine the two PSF-subtracted target images based on the WCS information. \n",
    "- Testing for LYOT, 1140C/FQPM and 1550C/FQPM datasets (using the updated PSFMASK Reference Files provided).\n",
    "- Testing of multiple integration images (current dataset treated as only single integration images).\n",
    "- Testing of data that has been processed through stage 1 and 2 pipeline modules.\n",
    "\n",
    "[Top of Page](#title_ID)\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "## About this Notebook\n",
    "**Authors:** \n",
    "- Bryony F. Nickson (Staff Scientist, *MIRI Branch*) \n",
    "- J. Brendan Hagan\n",
    "- Jonathan Aguilar (Staff Scientist, *MIRI Branch*)\n",
    "\n",
    "<br> **Updated On:** 01/12/2022\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
